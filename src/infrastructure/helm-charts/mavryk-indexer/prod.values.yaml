instances:
  dev:
    dipdup:
      initialWipe: false
      image:
        registry: docker.io
        repository: mavrykdynamics/mavryk-indexer
        tag: v0.35.0
        pullPolicy: IfNotPresent
        pullSecret: docker-pull-credentials
      metrics:
        serviceMonitor:
          namespace: kube-prometheus-stack
      database:
        backup:
          enabled: false
      env:
        - name: POSTGRES_DB
          value: dipdup-dev
        - name: POSTGRES_HOST
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_HOST_DEV
        - name: POSTGRES_PORT
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_PORT_DEV
        - name: POSTGRES_USERNAME
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_USERNAME_DEV
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_PASSWORD_DEV
        - name: ADMIN_SECRET
          valueFrom:
            secretKeyRef:
              name: indexer
              key: HASURA_GRAPHQL_ADMIN_SECRET
        - name: HASURA_URL
          value: http://hasura-dev.mavryk-indexer.svc.cluster.local:8080
        - name: TZKT_GHOSTNET_URL
          value: https://api.ghostnet.tzkt.io
        - name: TZKT_MAINNET_URL
          value: https://api.tzkt.io
    hasura:
      enabled: true
      image:
        registry: docker.io
        repository: hasura/graphql-engine
        tag: v2.15.2
      hpa:
        enabled: false
      resources:
        enabled: true
        requests:
          memory: 1000Mi
          cpu: 1000m
        limits:
          memory: 2000Mi
          cpu: 1500m
      ingress:
        service:
          name: hasura-dev
        enabled: true
        host: api-dev.mavryk.finance
        secretName: api-dev-mavryk-tls
      databaseURLKeyInSecret: HASURA_GRAPHQL_DATABASE_URL_DEV
  prod:
    dipdup:
      initialWipe: false
      image:
        registry: docker.io
        repository: mavrykdynamics/mavryk-indexer
        tag: v0.35.0
        pullPolicy: IfNotPresent
        pullSecret: docker-pull-credentials
      metrics:
        serviceMonitor:
          namespace: kube-prometheus-stack
      database:
        backup:
          enabled: true
          env:
            - name: POSTGRES_DB
              value: dipdup
            - name: PGHOST
              valueFrom:
                secretKeyRef:
                  name: indexer
                  key: POSTGRES_HOST_PROD
            - name: PGPORT
              valueFrom:
                secretKeyRef:
                  name: indexer
                  key: POSTGRES_PORT_PROD
            - name: PGUSER
              valueFrom:
                secretKeyRef:
                  name: indexer
                  key: POSTGRES_USERNAME_PROD
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: indexer
                  key: POSTGRES_PASSWORD_PROD
            - name: BACKUP_RETENTION_IN_DAYS
              value: '7'
            - name: BACKUP_FOLDER
              value: '/usr/indexer-backup'
      env:
        - name: POSTGRES_DB
          value: dipdup
        - name: POSTGRES_HOST
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_HOST_PROD
        - name: POSTGRES_PORT
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_PORT_PROD
        - name: POSTGRES_USERNAME
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_USERNAME_PROD
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_PASSWORD_PROD
        - name: ADMIN_SECRET
          valueFrom:
            secretKeyRef:
              name: indexer
              key: HASURA_GRAPHQL_ADMIN_SECRET
        - name: HASURA_URL
          value: http://hasura-prod.mavryk-indexer.svc.cluster.local:8080
        - name: TZKT_GHOSTNET_URL
          value: https://api.ghostnet.tzkt.io
        - name: TZKT_MAINNET_URL
          value: https://api.tzkt.io
    hasura:
      enabled: true
      image:
        registry: docker.io
        repository: hasura/graphql-engine
        tag: v2.15.2
      hpa:
        enabled: true
      resources:
        enabled: true
        requests:
          memory: 1000Mi
          cpu: 1000m
        limits:
          memory: 2000Mi
          cpu: 1500m
      ingress:
        service:
          name: hasura-prod2
        enabled: true
        host: api.mavryk.finance
        secretName: api-mavryk-tls
      databaseURLKeyInSecret: HASURA_GRAPHQL_DATABASE_URL_PROD
  prod2:
    dipdup:
      initialWipe: false
      image:
        registry: docker.io
        repository: mavrykdynamics/mavryk-indexer
        tag: v0.35.0
        pullPolicy: IfNotPresent
        pullSecret: docker-pull-credentials
      metrics:
        serviceMonitor:
          namespace: kube-prometheus-stack
      database:
        backup:
          enabled: true
          env:
            - name: POSTGRES_DB
              value: dipdup
            - name: PGHOST
              valueFrom:
                secretKeyRef:
                  name: indexer
                  key: POSTGRES_HOST_PROD_2
            - name: PGPORT
              valueFrom:
                secretKeyRef:
                  name: indexer
                  key: POSTGRES_PORT_PROD_2
            - name: PGUSER
              valueFrom:
                secretKeyRef:
                  name: indexer
                  key: POSTGRES_USERNAME_PROD_2
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: indexer
                  key: POSTGRES_PASSWORD_PROD_2
            - name: BACKUP_RETENTION_IN_DAYS
              value: '7'
            - name: BACKUP_FOLDER
              value: '/usr/indexer-backup'
      env:
        - name: POSTGRES_DB
          value: dipdup
        - name: POSTGRES_HOST
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_HOST_PROD_2
        - name: POSTGRES_PORT
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_PORT_PROD_2
        - name: POSTGRES_USERNAME
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_USERNAME_PROD_2
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_PASSWORD_PROD_2
        - name: ADMIN_SECRET
          valueFrom:
            secretKeyRef:
              name: indexer
              key: HASURA_GRAPHQL_ADMIN_SECRET
        - name: HASURA_URL
          value: http://hasura-prod2.mavryk-indexer.svc.cluster.local:8080
        - name: TZKT_GHOSTNET_URL
          value: https://api.ghostnet.tzkt.io
        - name: TZKT_MAINNET_URL
          value: https://api.tzkt.io
    hasura:
      enabled: true
      image:
        registry: docker.io
        repository: hasura/graphql-engine
        tag: v2.15.2
      hpa:
        enabled: true
      resources:
        enabled: true
        requests:
          memory: 1000Mi
          cpu: 1000m
        limits:
          memory: 2000Mi
          cpu: 1500m
      ingress:
        enabled: false
        service:
          name:
        host:
        secretName:
      databaseURLKeyInSecret: HASURA_GRAPHQL_DATABASE_URL_PROD_2
  staging:
    dipdup:
      initialWipe: false
      image:
        registry: docker.io
        repository: mavrykdynamics/mavryk-indexer
        tag: v0.35.0
        pullPolicy: IfNotPresent
        pullSecret: docker-pull-credentials
      metrics:
        serviceMonitor:
          namespace: kube-prometheus-stack
      database:
        backup:
          enabled: true
          env:
            - name: POSTGRES_DB
              value: dipdup-staging
            - name: PGHOST
              valueFrom:
                secretKeyRef:
                  name: indexer
                  key: POSTGRES_HOST_STAGING
            - name: PGPORT
              valueFrom:
                secretKeyRef:
                  name: indexer
                  key: POSTGRES_PORT_STAGING
            - name: PGUSER
              valueFrom:
                secretKeyRef:
                  name: indexer
                  key: POSTGRES_USERNAME_STAGING
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: indexer
                  key: POSTGRES_PASSWORD_STAGING
            - name: BACKUP_RETENTION_IN_DAYS
              value: '7'
            - name: BACKUP_FOLDER
              value: '/usr/indexer-backup'
      env:
        - name: POSTGRES_DB
          value: dipdup-staging
        - name: POSTGRES_HOST
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_HOST_STAGING
        - name: POSTGRES_PORT
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_PORT_STAGING
        - name: POSTGRES_USERNAME
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_USERNAME_STAGING
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: indexer
              key: POSTGRES_PASSWORD_STAGING
        - name: ADMIN_SECRET
          valueFrom:
            secretKeyRef:
              name: indexer
              key: HASURA_GRAPHQL_ADMIN_SECRET
        - name: HASURA_URL
          value: http://hasura-staging.mavryk-indexer.svc.cluster.local:8080
        - name: TZKT_GHOSTNET_URL
          value: https://api.ghostnet.tzkt.io
        - name: TZKT_MAINNET_URL
          value: https://api.tzkt.io
    hasura:
      enabled: true
      image:
        registry: docker.io
        repository: hasura/graphql-engine
        tag: v2.15.2
      hpa:
        enabled: true
      resources:
        enabled: true
        requests:
          memory: 1000Mi
          cpu: 1000m
        limits:
          memory: 2000Mi
          cpu: 1500m
      ingress:
        service:
          name: hasura-staging
        enabled: true
        host: api-staging.mavryk.finance
        secretName: api-staging-mavryk-tls
      databaseURLKeyInSecret: HASURA_GRAPHQL_DATABASE_URL_STAGING

# pgadmin4 module values
pgadmin4:
  enabled: true
  replicaCount: 1

  ## pgAdmin4 container image
  ##
  image:
    registry: docker.io
    repository: dpage/pgadmin4
    # Overrides the image tag whose default is the chart appVersion.
    tag: '6.12'
    pullPolicy: IfNotPresent

  ## Deployment annotations
  annotations: {}

  ## priorityClassName
  priorityClassName: ''

  ## Deployment entrypoint override
  ## Useful when there's a requirement to modify container's default:
  ## https://www.vaultproject.io/docs/platform/k8s/injector/examples#environment-variable-example
  ## ref: https://github.com/postgres/pgadmin4/blob/master/Dockerfile#L206
  # command: "['/bin/sh', '-c', 'source /vault/secrets/config && <entrypoint script>']"

  service:
    type: ClusterIP
    port: 80
    targetPort: 80
    # targetPort: 4181 To be used with a proxy extraContainer
    portName: http

    annotations:
      {}
      ## Special annotations at the service level, e.g
      ## this will set vnet internal IP's rather than public ip's
      ## service.beta.kubernetes.io/azure-load-balancer-internal: "true"

    ## Specify the nodePort value for the service types.
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
    ##
    # nodePort:

  ## Pod Service Account
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  ##
  serviceAccount:
    # Specifies whether a service account should be created
    create: false
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ''

  ## Strategy used to replace old Pods by new ones
  ## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  ##
  strategy:
    {}
    # type: RollingUpdate
    # rollingUpdate:
    #   maxSurge: 0
    #   maxUnavailable: 1

  ## Server definitions will be loaded at launch time. This allows connection
  ## information to be pre-loaded into the instance of pgAdmin4 in the container.
  ## Ref: https://www.pgadmin.org/docs/pgadmin4/latest/import_export_servers.html
  ##
  serverDefinitions:
    ## If true, server definitions will be created
    ##
    enabled: true

    servers:
      # dipdup:
      #   Name: 'Dipdup'
      #   Group: 'Servers'
      #   Port: 5432
      #   Username: 'dipdup'
      #   Host: '10.10.11.5'
      #   SSLMode: 'prefer'
      #   MaintenanceDB: 'dipdup'

  networkPolicy:
    enabled: true

  ## Ingress
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ingress:
    enabled: false
    annotations:
      {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    # ingressClassName: ""
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: Prefix
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # Additional config maps to be mounted inside a container
  # Can be used to map config maps for sidecar as well
  extraConfigmapMounts:
    []
    # - name: certs-configmap
    #   mountPath: /etc/ssl/certs
    #   subPath: ca-certificates.crt # (optional)
    #   configMap: certs-configmap
    #   readOnly: true

  extraSecretMounts:
    []
    # - name: pgpassfile
    #   secret: pgpassfile
    #   subPath: pgpassfile
    #   mountPath: "/var/lib/pgadmin/storage/pgadmin/file.pgpass"
    #   readOnly: true

  ## Additional volumes to be mounted inside a container
  ##
  extraVolumeMounts: []

  ## Specify additional containers in extraContainers.
  ## For example, to add an authentication proxy to a pgadmin4 pod.
  extraContainers: |
    # - name: proxy
    #   image: quay.io/gambol99/keycloak-proxy:latest
    #   args:
    #   - -provider=github
    #   - -client-id=
    #   - -client-secret=
    #   - -github-org=<ORG_NAME>
    #   - -email-domain=*
    #   - -cookie-secret=
    #   - -http-address=http://0.0.0.0:4181
    #   - -upstream-url=http://127.0.0.1:3000
    #   ports:
    #     - name: proxy-web
    #       containerPort: 4181

  ## Provide the name for an existing secret.
  ## Useful to avoid specifying password and server config in YAML files
  existingSecret: ''

  ## pgAdmin4 startup configuration
  ## Values in here get injected as environment variables
  ## Needed chart reinstall for apply changes
  env:
    # can be email or nickname
    email: tristan@tezosdynamics.com
    password: ''
    # pgpassfile: /var/lib/pgadmin/storage/pgadmin/file.pgpass

    # set context path for application (e.g. /pgadmin4/*)
    # contextPath: /pgadmin4

    ## If True, allows pgAdmin4 to create session cookies based on IP address
    ## Ref: https://www.pgadmin.org/docs/pgadmin4/latest/config_py.html
    ##
    enhanced_cookie_protection: 'False'

    ## Add custom environment variables that will be injected to deployment
    ## Ref: https://www.pgadmin.org/docs/pgadmin4/latest/container_deployment.html
    ##
    variables: []
    # - name: PGADMIN_LISTEN_ADDRESS
    #   value: "0.0.0.0"
    # - name: PGADMIN_LISTEN_PORT
    #   value: "8080"

  ## Additional environment variables from ConfigMaps
  envVarsFromConfigMaps:
    []
    # - array-of
    # - config-map-names

  ## Additional environment variables from Secrets
  envVarsFromSecrets:
    []
    # - array-of
    # - secret-names

  persistentVolume:
    ## If true, pgAdmin4 will create/use a Persistent Volume Claim
    ## If false, use emptyDir
    ##
    enabled: false

    ## pgAdmin4 Persistent Volume Claim annotations
    ##
    annotations: {}

    ## pgAdmin4 Persistent Volume access modes
    ## Must match those of existing PV or dynamic provisioner
    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    accessModes:
      - ReadWriteOnce

    ## pgAdmin4 Persistent Volume Size
    ##
    size: 500Mi

    ## pgAdmin4 Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    storageClass: 'do-block-storage'
    # existingClaim: ""

  ## Additional volumes to be added to the deployment
  ##
  extraVolumes: []

  ## Security context to be added to pgAdmin4 pods
  ##
  securityContext:
    runAsUser: 5050
    runAsGroup: 5050
    fsGroup: 5050

  ## pgAdmin4 readiness and liveness probe initial delay and timeout
  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  ##
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 15
    successThreshold: 1
    failureThreshold: 3

  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 15
    successThreshold: 1
    failureThreshold: 3

  ## Required to be enabled pre pgAdmin4 4.16 release, to set the ACL on /var/lib/pgadmin.
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ##
  VolumePermissions:
    ## If true, enables an InitContainer to set permissions on /var/lib/pgadmin.
    ##
    enabled: false

  ## Additional InitContainers to initialize the pod
  ##
  extraInitContainers: |
    #   - name: add-folder-for-pgpass
    #     image: "dpage/pgadmin4:latest"
    #     command: ["/bin/mkdir", "-p", "/var/lib/pgadmin/storage/pgadmin"]
    #     volumeMounts:
    #       - name: pgadmin-data
    #         mountPath: /var/lib/pgadmin
    #     securityContext:
    #       runAsUser: 5050

  containerPorts:
    http: 80

  resources:
    {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  ## Horizontal Pod Autoscaling
  ## ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
  #
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  ## Node labels for pgAdmin4 pod assignment
  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}

  ## Node tolerations for server scheduling to nodes with taints
  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  ##
  tolerations: []

  ## Pod affinity
  ##
  affinity: {}

  ## Pod annotations
  ##
  podAnnotations: {}

  ## Pod labels
  ##
  podLabels:
    {}
    # key1: value1
    # key2: value2

  init:
    ## Init container resources
    ##
    resources: {}

  ## Define values for chart tests
  test:
    ## Container image for test-connection.yaml
    image:
      registry: docker.io
      repository: busybox
      tag: latest
    ## Resources request/limit for test-connection Pod
    resources: {}
    #     limits:
    #       cpu: 25m
    #       memory: 16Mi
    #     requests:
    #       cpu: 50m
    #       memory: 32Mi
    ## Security context for test-connection Pod
    securityContext:
      runAsUser: 5051
      runAsGroup: 5051
      fsGroup: 5051
